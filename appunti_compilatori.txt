24/09/24

Compilatore: componente di una cosidetta "toolchain" di programmi il cui obiettivo è creare eseguibili a partire da programmi sorgenti

Altri componenti della "toolchain":
    - precompilatore: inclusione di file (#include), definizione/espansione di macro (#define) e compilazione condizionale (#ifdef, #if, #ifndef)
    - assemblatore: genera il codice oggetto 
    - linker (statico o dinamico): collega le librerie statiche e crea l'eseguibile finale

sorgente (hw.cpp) --> PREPROCESSORE --> pre elaborato o translation unit (hw.ii) --> COMPILATORE (cc1plus) --> assembly (hw.s) --> ASSEMBLER (as) --> codice oggetto (hw.o) --> LINKER (ld) --> eseguibile (hw) --> processo in esecuzione (input: librerie dinamiche) --> output

GCC (GNU Compiler Collection): suite in grado di compilare principalmente programmi in C/C++
    - cpp: preprocessore C/C++
    - cc1/cc1plus: compilatore vero e proprio
    - as: programma assemblatore
    - ld: linker

- Preprocessing
    > cpp -o hw.ii hw.cpp
- Compilazione
    > cc1plus -o hw.s hw.ii 2>/dev/null
- Assemblaggio
    > as -o hw.o hw.s
- Linking (collect2: invocatore del linker)
    > g++ -v -o hw.o --> il driver g++ invoca il linker usando il comando collect2
- Esecuzione
    ./hw

Compilatore vs Interprete

Compilatore
Nei linguaggi compilati, il codice sorgente viene tradotto interamente in codice macchina da un programma chiamato compilatore prima dell'esecuzione
sorgente --> compilatore --> eseguibile (in linguaggio macchina) --> macchina fisica (interpreta il binario) --> output
    - Compilazione anticipata: prima compilazione poi esecuzione
    - Velocità di esecuzione: l'esecuzione è più veloce in quanto il codice è già tradotto in istruzioni macchina
    - Verifica di errori: la maggior parte degli errori (sintattici o semantici) viene rilevata durante la compilazione
    - Portabilità limitata: il codice compilato è strettamente legato all'architettura della macchina su cui è stato compilato 

Interprete
Nei linguaggi interpretati, il codice sorgente viene tradotto ed eseguito riga per riga da un programma chiamato interprete
L'interprete legge il codice sorgente e lo esegue direttamente, senza produrre un file eseguibile seperato
sorgente --> interprete --> output
    - Velocità di esecuzione: più lento nell'esecuzione, poichè l'interprete deve tradurre ogni istruzione mentre viene eseguita (inefficiente, spende molto tempo nell'analisi dell'input)
    - Flessibilità: maggiore flessibilità e portabilità poichè l'interprete può essere eseguito su diverse piattaforme
    - Debugging più semplice: eseguendo il codice riga per riga risulta più facile testare piccole porzioni di codice
    - Portabilità: il codice sorgente può essere eseguito su qualsiasi macchina che abbia un interprete compatibile 

Linguaggi ibridi: vengono prima compilati in bytecode, un formato intermedio, e poi eseguiti da una macchina virtuale (JVM per Java)
Anche Python a volte utilizza una compilazione intermedia in bytecode (.pyc) ma viene comunque interpretato da una macchina virtuale (l'interprete Python)

In generale, un'implementazione interpretata include anche un traduttore che è essenzialmente identico al front-end di un compilatore

OSSERVAZIONE: il bytecode è tipicamente l'assembler della macchina virtuale

Compilatore: modulo che effettua la traduzione da codice sorgente ad una qualche rappresentazione intermedia, esso è suddiviso a sua volta in 3 moduli:
    - front-end (compilatori e interpreti): prende il sorgente e produce una sua rappresentazione intermedia indipendente dal linguaggio e dalla macchina
    - middle-end: esegue un'ottimizzazione del codice intermedio
    - back-end: produce il codice per l'architettura target

Il front/middle/back-end è composto da 4/1/2 fasi
sequenza di caratteri --> ANALIZZATORE LESSICALE --> sequenza di token --> ANALIZZATORE SINTATTICO --> albero sintattico --> GENERATORE DI CODICE INTERMEDIO --> rappresentazione intermedia | --> GENERATORE DI CODICE --> codice macchina --> OTTIMIZZATORE DIPENDENTE DALLA TECNOLOGIA --> codice macchina

Fasi del front-end di un compilatore:
    - ANALIZZATORE LESSICALE (LEXER): raggruppa sequenze di caratteri in oggetti (TOKEN)
    - ANALIZZATORE SINTATTICO (PARSER): start run, prende una sequenza di token e indica se essi formano una struttura linguistica legale del linguaggio (correttezza sintattica)
    - ANALIZZATORE SEMANTICO: analisi dei tipi, controlla la corrispondenza del numero di parametri di una procedura
    - GENERATORE DI CODICE INTERMEDIO: produce un codice lineare

TABELLA DEI SIMBOLI: struttura dati (dizionario: mapping chiave-valore) che memorizza i simboli incontrati nell'analisi del sorgente

Esempio pratico:
position = initial + rate * 60

Analizzatore lessicale:
⟨id, 1⟩ (=) ⟨id, 2⟩ (+) ⟨id, 3⟩ (*) (60)

Analizzatore sintattico:
⟨id, 1⟩ = ⟨id, 2⟩ + ⟨id, 3⟩ * 60

Analizzatore semantico:
⟨id, 1⟩ = ⟨id, 2⟩ + ⟨id, 3⟩ * inttofloat(60)

Generatore di codice intermedio:
t1 = inttofloat(60)
t2 = id3 * t1
t3 = id2 + t2
id1 = t3

Ottimizzatore di codice:
t1 = id3 * 60.0
id1 = id2 + t1

Generatore di codice:
LDF R2, id3
MULF R2, R2, #60.0
LDF R1, id2
ADDF R1, R1, R2
STF id1, R1

Type Checking: controllo dei tipi (statico --> controllo a tempo di compilazione | dinamico --> controllo a tempo di esecuzione)
Scoping rules: regole che descrivono la visibilità (o scope) delle variabili all'interno del programma
Ambiente: mapping fra nomi e locazioni di memoria
Memoria: mapping fra locazioni di memoria e valori
Linguaggio funzionale: caratterizzato da un mapping diretto tra nome e valore, il programmatore ha visibilità del solo ambiente (e non della memoria)
l-value (left value): entità che ha una posizione in memoria e quindi può essere assegnato o modificato
    - ha un indirizzo in memoria
    - può essere usato per ricevere un valore
r-value (right value): rappresenta un qualsiasi valore o contenuto temporaneo che può essere assegnato (ma non modificato) a un l-value
    - non ha un indirizzo in memoria associato 
    - non può essere assegnato o modificato direttamente

26/09/24

Linguaggi formali: linguaggi definiti mediante un qualche apparato formale di natura matematica
    - è possibile stabilire se una "frase" è corretta (sintassi)
    - è possibile attribuire un ben preciso significato, senza ambiguità (semantica)

Linguaggi formali in informatica
- Linguaggi di programmazione: C/C++, Java, Python, ...
- Linguaggi di marcatura: HTML. XML, LaTeX
- Linguaggi di interrogazione: SQL, SPARQL, GraphLog
- Linguaggi di configurazione: sendmail, apache, iptables

ALFABETO: insieme finito di simboli (detti anche CARATTERI)
    - Σ per indicare un generico alfabeto
    - (a, b e c) per indicare un generico carattere utilizziamo le lettere iniziali dell'alfabeto latino

STRINGHE: sequenza di caratteri ∈ Σ
    - per indicare una stringa generica utilizziamo le ultime lettere dell'alfabeto latino (w, x, y, z)
    - per indicare una stringa generica utilizziamo le prime lettere dell'alfabeto greco (α, β, γ)
    - per indicare una stringa speciale (formata da zero caratteri) o vuota usiamo ϵ
    - per evitare ambiguità racchiuderemo le stringhe fra coppie di apici (o doppi apici)

Operazioni sulle stringhe
- Concatenazione: unione di due stringhe, una di seguito all'altra
    x = Linguaggi y = formali --> xy = Linguaggiformali
    - associativa ( (A*B)*C = A*(B*C) ), ma non commutativa (A*B != B*A)
    - la stringa vuota ϵ è l'elemento neutro della concatenazione
- |x| lunghezza della stringa x
- x[i] carattere in posizione i, i = 0, . . . , |x| − 1
- Una sottostringa di x é una stringa formata dai caratteri xi, xi+1, . . . , xj, per opportuni valori di i e j, 0 ≤ i ≤ j < n
- x^R indica la stringa ottenuta rovesciando i caratteri di x
    x = Roma --> x^R = amoR

LINGUAGGI
Un linguaggio su un dato alfabeto Σ è un insieme di stringhe di caratteri (o simboli) ∈ Σ
- Esempio di linguaggio con un numero di stringhe finito
    L2 = {00,01,10,11} --> definito su B e formato da 4 stringhe da 2 caratteri ciascuna

Operazioni con i linguaggi
- operazioni insiemistiche (unione, intersezione, differenza, ...)
- concatenazione
    M e N linguaggi dello stesso alfabeto Σ
    L = MN = {z ∈ Σ* : ∃ x ∈ M, ∃ y ∈ N | z = xy}
    elemento neutro: stringa vuota {ϵ}
- potenza n-esima
    L^0 = {ϵ}
    L^n = L^n−1 * L, n > 0
- chiusura (riflessiva)
    L* = ∪ (n=0 to ∞) L^n = L^0 ∪ L^1 ∪ L^2 ∪ ...
    Esempio:
        B* = ∪ (n=0 to ∞) {0,1}^n
        = {0, 1}^0 ∪ {0, 1}^1 ∪ {0, 1}^2 ∪ . . .
        = {ϵ} ∪ {0, 1} ∪ {00, 01, 10, 11} . . .
        B*: insieme di tutte le stringhe binarie
    Σ*: insieme di tutte le stringhe su un alfabeto Σ
- chiusura (non riflessiva): L^+ = LL*
    L^+ = ∪ (n=1 to ∞) L^n = L^1 ∪ L^2 ∪ ...
- riflessione di linguaggio L su alfabeto Σ
    L^R = {x ∈ Σ* : ∃y ∈ L | x = y^R}
- |L| numero stringhe di un linguaggio finito
    |L| = N se L è infinito

Specifica di linguaggi
Se il linguaggio è infinito è comunque possibile descriverlo con quantità finita di informazione
Esempio:
    L0 = {x ∈ B* | x = y0, y ∈ B*}

Specifica riconoscitiva
Si tratta di definire il linguaggio tramite un algoritmo decisionale, ossia il cui output è binario: yes/no True/False, 0/1, ...
Dato A un algoritmo di decisione, Σ alfabeto generico: 
La = {x ∈ Σ* | A(x) = True}
Il linguaggio C++ è l'insieme delle stringhe sull'alfabeto ASCII (programmi) per cui il compilatore C++ (l'algoritmo) non produce errore

Specifica generativa
Si danno delle "regole" con cui è possibile generare tutte e sole le stringhe del linguaggio che si vuole specificare
I formalismi più importanti sono: --> strumenti fondamentali per definire il comportamento di lexer e parser
    - espressioni regolari
    - grammatica context-free

Linguaggi regolari
Un linguaggio L su alfabeto Σ = {a1, ..., an} si dice "regolare" se può essere espresso usando un numero finito di operazioni di 
concatenazione, unione e chiusura riflessiva a partire dai suoi linguaggi unitari {a1}, ..., {an}
    - {ϵ}, {a1}, . . . , {an} sono linguaggi regolari
    - se R1 ed R2 sono linguaggi regolari, allora R1 ∪ R2 e R1R2 sono linguaggi regolari
    - se R è un linguaggio regolare allora R* è un linguaggio regolare 

Linguaggio unitario: linguaggio costituito da un singolo carattere di Σ
Esempio:
    - {C++} è concatenazione dei linguaggi unitari {C}, {+}, {+}
    - {Python} è concatenazione dei linguaggi unitari {P}, {y}, {t}, {h}, {o}, {n}
    - {x,y,z} è regolare perchè esprimibile come unione dei linguaggi regolari {x}, {y} e {z}
    - {C++,Python} è regolare perchè unione di due linguaggi regolari
Ogni linguaggio finito è esprimibile come unione di concatenazioni di linguaggi unitari

Espressioni regolari
Dato un alfabeto Σ sono un formalismo (cioè a loro volta sono linguaggi) per definire linguaggi regolari
Le epressioni regolari pure (e.r) riflettono le costruzioni dei linguaggi regolari 
    Base
        - ϵ è un'espressione regolare che denota il linguaggio composto dalla sola stringa vuota ϵ
        - per ogni a ∈ Σ, a è un'e.r. che denota il linguaggio unitario {a}
    Ricorsione --> Se E ed F sono e.r. che denotano, rispettivamente, i linguaggi E ed F, allora la scrittura:
        - EF è un'e.r. che denota il linguaggio EF (concatenazione)
        - E|F (o anche E + F) è un'e.r. che denota il linguaggio E ∪ F (unione)
        - E* è un'e.r. che denota il linguaggio E* (chiusura riflessiva)
    Parentesi --> Se E è un'e.r., la scrittura (E) è un'e.r. equivalente alla prima, cioè che denota lo stesso insieme di stringhe

01/10/24

prefisso: sottostringa che sta all'inizio

Esempi:
- L'espressione regolare 0|1*10 su B (interpretabile come 0|((1*)10), in base alle regole di precedenza) denota il linguaggio R1 = {0, 10, 110, 1110, . . .}
- Il linguaggio R1 è chiaramente differente dal linguaggio R2 su B definito dall'espressione regolare (0|1)*10, che consiste di tutte le stringhe binarie che terminano con 10
- Posto Σ = {a, b, c}, l'espressione regolare a(b|c)*a denota il linguaggio R3 su Σ costituito dalle stringhe che iniziano e terminano con il carattere a e che non contengono altre a
- La scrittura (1|01)*(0|ϵ) denota il linguaggio delle stringhe su B di lunghezza almeno 1 che non contengono due caratteri 0 consecutivi

Problemi pratici
- Nelle regole di composizione delle e.r. non esiste la possibilità di esprimere la negazione di un carattere a
- Allo stesso modo non esiste un operatore per indicare una potenza definita di un insieme di stringhe

Metacaratteri e regole aggiuntive
- Come sappiamo, i simboli dell'alfabeto sono detti anche "caratteri"
- Nella descrizione formale del linguaggio si usano però anche altri simboli, che non fanno parte dell'alfabeto
- Nel caso delle e.r., esempi di simboli usati per scopi descrittivi sono le parentesi e i simboli * e |
    Tali simboli sono detti metacaratteri (simboli astratti)
- Nelle e.r. estese (definite, ad es. sull'alfabeto ASCII) esistono metacaratteri che denotano opportuni sotto-insiemi di caratteri dell'alfabeto
    Ad esempio:
        - la scrittura [:alpha:] denota l'insieme dei caratteri alfabetici (rispetto al locale corrente)
        - [:digit:] denota l'insieme delle cifre decimali
        - [:alnum:] denota l'insieme dei caratteri alfabetici e numerici (le cifre)
- Le parentesi quadre sono metacaratteri
- Caratteri e metacaratteri inclusi fra parentesi quadre si intendono in or
    Ad esempio [_[:alnum:]] denota l'insieme dei caratteri alfanumerici unito il "trattino basso" (underscore)
- Il simbolo ^ come primo carattere all'interno di una coppia di parentesi quadre denota l'insieme dei caratteri dell'alfabeto, ad esclusione dei simboli che seguono
    Ad esempio [^[:alnum:]] denota l'insieme di tutti i caratteri che non sono alfanumerici

Problemi di matching
- Nella parte di front-end di compilatori e interpreti, il programma (analizzatore lessicale o lexer) riceve in input il testo (programma da compilare/eseguire)
  e un insieme di espressioni regolari, il lexer deve dire quale espressione descrive un opportuno prefisso del testo ancora da analizzatore
    Ad esempio, se l'input ancora da esaminare fosse 
        formula = 2*x**2
    il prossimo match trovato dal lexer dovrebbe essere formula (un caso di identificatore) piuttosto che for (un caso di parola chiave)

Esercizi di prova
NB: Il carattere * in un'espressione regolare è un quantificatore e indica che l'elemento che lo precede può comparire zero o più volte
1. Scrivere e.r per i linguaggi sull'alfabeto {a,b} composti dalle stringhe contenenti:
    - al più due a --> b* | b*ab* | b*ab*ab*
    - un numero dispari b --> (a*ba*b)*a*ba*
2. Scrivere un'e.r. per il linguaggio sull'alfabeto {a, b, c} così definito: {a^n b^m c^k | m = 0 ⇒ k = 3} --> se m = 0 (quindi non ci sono b) allora k = 3 (ci devono essere esattamente 3 c)
    a*(bb*c* | ccc)
3. Scrivere un'e.r. per il linguaggio sull'alfabeto {a, b, c}, costituito dalle stringhe in cui ogni occorrenza di b è seguita da almeno una c  
    (a | c | bc)*
4. Qual è il linguaggio descritto dalla seguente espressione regolare estesa: [ab]{3}∗[ab] --> [ab] = a | b
    abbaab, aaaabb, ...
    ((a | b)(a | b)(a | b)) (a | b) --> e.r base
5. Scrivere un'espressione regolare per definire il linguaggio delle stringhe sull'alfabeto {0, 1} che non contengono tre 1 di fila
    (0 | 10 | 110)* (1 | 11)0*

Espressioni regolari che ci saranno utili
- E.r. estesa per identificatori composti dal carattere underscore, lettere e numeri e inizianti per lettera o underscore
    [a − zA − Z_][a − zA − Z0 − 9_]∗
- E.r. per numeri in virgola fissa (interi inclusi)
    (0|[1 − 9][0 − 9]∗)\.?[0 − 9]∗
- E.r. per numeri in virgola mobile
    (0|[1 − 9][0 − 9]∗)\.?[0 − 9] ∗ ([eE][−+]?[0 − 9]+)

Le espressioni regolari sono lo strumento che utilizzeremo per programmare un lexer

Lexer (Analizzatore Lessicale)
- Il compito principale del lexer è di trasformare la sequenza di caratteri che costituisce l'input del compilatore (cioè il programma) in una sequenza di token
- Il lexer agisce come subroutine del parser e, ad ogni chiamata, restituisce a quest'ultimo un token

Token --> oggetto astratto (rappresentato con una struct) con le seguenti proprietà: --> esempi di token: numeri, identificatori e le parole riservate di un linguaggio di programmazione
    - deve avere un nome (token name, sempre in grassetto) --> identificatore che deve avere lo stesso significato per lexer e parser
    - alcuni token (numeri, identificatori e costanti letterali) hanno anche un token value 
    - alcuni altri token (keyword, parentesi, operatori relazionali o aritmetici)
    - la posizione dove si trova il token (location)

Esempio:
Supponiamo che la porzione di input da analizzare abbia come prefisso
    somma = 0
Alle richieste del parser, il lexer restituisce in sequenza i token
    - (id, "somma")
    - assignment
    - (number,0)

Pattern, lessemi e (nomi di) token

Token name          Pattern                     Esempio di lessema (sottostringa matchata)
id                  [:alpha:][:alnum:]*         pippo1
number              [+- ][1-9][:digit:]*        -3.14
comparison          < | > | <= | >= | = | !=    <   
literal             [:alpha:]                   "Pi greco"
if                  if                          if
while               while                       while

Compiti del lexer
- Il lexer è l'unico modulo del compilatore che legge l'input testuale
- Lo scanner è un modulo separato del lexer che effettua la lettura del testo
- Il lexer vero e proprio, nel processo di tokenizzazione, procede anche a riconoscere e "filtrare" commenti, spazi e altri caratteri di separazione
- Deve inoltre associare gli eventuali errori trovati da altri moduli del compilatore alle posizione dove tali errori si sono verificati

In linux:
flex --> generatore di lexer
bison --> generatore di parser

Lex: strumento per generare analizzatori lessicali
    - software in grado di generare automaticamente un altro programma che riconosce stringhe di un linguaggio regolare
    - l'input del programma Lex è costituito da un insieme di espressioni regolari / pattern da riconoscere
    - inoltre, ad ogni espressione regolare E, l'utente associa un'azione, espressa sotto forma di codice in linguaggio C/C++
    - tale codice andrà in esecuzione quando l'analizzatore lessicale prodotto da Lex avrà riconosciuto un lessema descritto da E

Schema d'uso di Lex
Sorgente Lex (lexer.l) --> Compilatore Lex --> lex.yy.c / lex.yy.cc
lex.yy.cc / lex.yy.cc --> Compilatore C/C++ --> a.out
charstring --> Running a.out --> token sequence

Struttura di un programma Lex
- Un generico programma Lex contiene tre sezioni, separate dalla sequenza %%
    Dichiarazioni   
    %%
    Regole di traduzione
    %%
    Funzioni ausiliarie
- La sezione "Dichiarazioni" può contenere definizione di costanti/variabili, specifica di header file e, soprattutto, definizioni regolari, cioè espressioni regolari "con un nome"
- La sezione intermedia specifica le "regole di traduzione", ovvero le descrizioni delle azioni che devono essere eseguite a seguito del riconoscimento dell'istanza di un pattern
    riconoscimento di un lessema che matcha un'espressione regolare
- L'ultima sezione può contenere funzioni aggiuntive

Esempio di "tokenizer":

%{
# include <iostream>
using namespace std;
%}

DIGIT [0-9]
DIGIT1 [1-9]

/* read only one input file */
%option noyywrap

%%
"+"                 { cout << " operatore <" << yytext [0] << ">" << endl ; }
"-"                 { cout << " operatore <" << yytext [0] << ">" << endl ; }
"="                 { cout << " operatore <" << yytext [0] << ">" << endl ; }
{DIGIT1}{DIGIT}*    { cout << " numero <" << yytext << ">" << endl ; }
.                   { cout << " Token sconosciuto <" << yytext [0] << ">" << endl ; }
%%

int main (int argc, char ** argv) {
    FlexLexer * lexer = new yyFlexLexer;
    lexer -> yylex();
    return 0;
}

Analisi del codice
- Al termine dell'esecuzione, yylex invoca il metodo yywrap
- Questo può quindi essere utilizzato per aprire un secondo file di input e chiamare nuovamente yylex
- Se viene utilizzata l'opzione noyywrap, il metodo yywrap non viene invocato e non deve essere ridefinito

yytext: varabile globale in cui il lexer va a mettere il lessema che ha matchato il pattern (o espressione regolare)
%option noyywrap --> opzione che permette di leggere solo un file di input

Compilazione:
flex++ -o simpletok.cc simpletok.l --> compilazione del programma Lex
clang++/g++ -o simpletok simpletok.cc --> compilazione del file C++

Esecuzione:
echo "12+13=25" | ./simpletok --> esecuzione con input

Output:
    numero <12>
    operatore <+>
    numero <13>
    operatore <=>
    numero <25>

echo "y+=y-1" | ./simpletok --> esecuzione con input 

Output:
    Token sconosciuto <y>
    operatore <+>
    operatore <=>
    Token sconosciuto <y>
    operatore <->
    numero <1>

03/10/24

Applicazioni "standalone" --> non richiedono la presenza di altri programmi o applicazioni hardware per funzionare
- Uno strumento come Lex può essere utilmente impiegato anche per la creazione di applicazioni standalone
- Ad esempio, il programma Lex riportato nelle slide seguenti "emula" l'utility wc di Linux; conta cioè caratteri, parole e linee presenti in un file
- Del programma daremo in realtà due versioni, di fatto identiche ma organizzate in modo diverso,
 la prima in un file singolo e la seconda su due file, che andremo a compilare separatamente
- I programmi mettono in evidenza l'esistenza di un'altra variabile globale, yyleng, che memorizza la lunghezza del lessema che ha provocato il match

Il comando wc realizzato con Lex (prima versione)
%{
#include <iostream>
using namespace std;

unsigned long charCount = 0, wordCount = 0, lineCount = 0;
%}

word [^ \t\n]+
eol \n

%option noyywrap

%%
{word}        {wordCount ++; charCount += yyleng ;}
{eol}         {charCount ++; lineCount ++;}
.             charCount ++;
%%

int main (int argc, char** argv) {
    FlexLexer * lexer = new yyFlexLexer;
    lexer -> yylex();
    cout << lineCount << " " << wordCount << " " << charCount << endl;
}

wcsep.l --> File Lex, senza main, per wc (seconda versione)
%{
#include <iostream>
using namespace std;

unsigned long charCount = 0, wordCount = 0, lineCount = 0;
%}

word [^ \t\n]+         // uno o più caratteri diversi da quelli indicati (spazio, tabulazione e newline) 
eol \n

%option noyywrap

%%
{word}        {wordCount++; charCount += yyleng;}
{eol}         {charCount++; lineCount++;}
.             charCount++;
%%

wcmain.cpp --> Main program per l'applicazione wc
#include <iostream>
#include <FlexLexer.h>
using namespace std;

extern unsigned long charCount , wordCount , lineCount;

int main() {
    FlexLexer * lexer = new yyFlexLexer;
    lexer -> yylex ();
    cout << lineCount << " " << wordCount << " " << charCount << endl;
    return 0;
}

Per la compilazione:
flex++ -o wcsep.cpp wcsep.l
g++ -c wcsep.cpp
g++ -c wcmain.cpp
g++ -o wc wcsep.cpp wcmain.cpp

Esecuzione:
echo "y = 12+17; " | ./wc

Output:
    1 3 12 --> 1: linecount 3: wordCount 12: charCount
    
Il linguaggio LFM
- LFM è un semplice linguaggio che ci permetterà di dare concretezza ai concetti teorici analizzati a lezione
- In questo primo "assaggio", implementiamo un lexer in grado di "tokenizzare" i lessemi che possono essere presenti solo in alcune della frasi legali di LFM
- Diamo alcune esempi di tali frasi:
    1 external printf(x) --> descrive l'utilizzo di funzioni esterne
    2 function MCD(x y) --> descrive il prototipo di funzione
    3 if y=0:x ; True:MCD(y,x%y) end --> descrive il costrutto condizionale che insieme alla chiamata di funzione, è l'unico costrutto di controllo del linguaggio

Lessico di LFM (prima versione)
Fanno parte del lessico:
    - Gli operatori aritmetici +, -, * (che denota la moltiplicazione), / e % (che denota il resto nella divisione intera)
    - Gli operatori relazionali =, >, <, >= e <=
    - Le parentesi tonde, la virgola, il punto e virgola e i due punti
    - Le due parole chiave external e function
    - I numeri interi
    - Gli identificatori

lexer.l
%{
#include <iostream>
using namespace std;
%}

/* read only one input file */
%option noyywrap

id      [a-zA-Z][a-zA-Z_0-9]*
integer  0|[1-9][0-9]∗
sep      [ \t\n]

%%
{sep}            {}
"%"              {cout << "- Operatore: " << yytext[0] << endl; }
":"              {cout << "- Separatore condizione/azione: " << yytext[0] << endl; }
";"              {cout << "- Separatore alternative condizionali: " << yytext[0] << endl; }
"="              {cout << "- Test uguaglianza: " << yytext[0] << endl; }
"("              {cout << "- Parentesi aperta: " << yytext[0] << endl; }
")"              {cout << "- Parentesi chiusa: " << yytext[0] << endl; }
","              {cout << "- Separatore argomenti: " << yytext[0] << endl; }
{integer}        { errno = 0;
                   int n = stoi(yytext, NULL);
                   cout << "- Numero: " << n << endl; 
                 }
"function"       {cout << "- Parola chiave: " << yytext << endl; }
"external"       {cout << "- Parola chiave: " << yytext << endl; }
"if"             {cout << "- Parola chiave: " << yytext << endl; }
"end"            {cout << "- Parola chiave: " << yytext << endl; }
"True"           {cout << "- Costante logica: " << yytext << endl; }
{id}             {cout << "- Identificatore: " << yytext << endl; }
.                {cout << "- Token sconosciuto: " << yytext[0] << endl; }
%%

int main(int argc, char** argv) {
    FlexLexer* lexer = new yyFlexLexer;
    lexer -> yylex();
    return 0;
}

Compilazione:
flex++ -o lexer.cpp lexer.l
g++ -o lexer lexer.cpp

Esecuzione:
echo "if y=0:x ; True:MCD(y,x%y) end" | ./lexer

Output:
    - Parola chiave: if
    - Identificatore: y
    - Test uguaglianza: =
    - Numero: 0
    - Separatore condizione/azione: :
    - Identificatore: x
    - Separatore alternative condizionali: ;
    - Costante logica: True
    - Separatore condizione/azione: :
    - Identificatore: MCD
    - Parentesi aperta: (
    - Identificatore: y
    - Separatore argomenti: ,
    - Identificatore: x
    - Operatore: %
    - Identificatore: y
    - Parentesi chiusa: )
    - Parola chiave: end

Automi finiti
In questo corso siamo interessati agli automi finiti in quanto descrivono lo stesso insieme di linguaggi (i linguaggi regolari) descritti da espressioni regolari
In particolare, da ogni espressione regolare è possibile costruire algoritmicamente un automa finito non deterministico da utilizzare nel riconoscimento di token

Definizione informale
- Un automa finito deterministico (AFD), può essere visto come un calcolatore elementare dotato di stato interno e supporto unidirezionale di input
- Il funzionamento dell'automa consiste di transizioni di stato a seguito della lettura di un simbolo da un dispositivo di input
- Ad ogni stato q sono in generale associate azioni (come la stampa di messaggi) che l'automa esegue quando transita in q

Descrizione formale
Un AFD M è una quintupla
    M = (Σ, Q, q0, Qf , δ),
in cui
    - Σ è l'alfabeto di input
    - Q è un insieme finito i cui elementi sono detti stati dell'automa
    - q0 è un elemento speciale di Q, detto stato iniziale
    - Qf ⊆ Q è l'insieme degli stati finali, detti anche di accettazione dell'input
    - δ è la funzione che determina le transizioni di stato
        Essa mappa coppie <stato, simbolo> in stati: δ : Q × Σ → Q

Computazioni di un automa
- Definibili in modo intuitivo come sequenza di passi
- Ad ogni passo, l'automa si trova in uno stato q (inizialmente q = q0), legge un simbolo x dall'input e transita nello stato δ(q, x)
- La computazione termina al verificarsi di una delle seguenti situazioni:
    - mancanza di input: non vi sono più simboli di input
    - transizione non specificata in corrispondenza dello stato attuale e del simbolo letto --> la funzione di transizione non è specificata
- Il numero di transizioni effettuate prima della terminazione è detto lunghezza della computazione e ne rappresenta una misura del costo

Rappresentazione di automi
- Un diagramma di transizione è un grafo i cui nodi ed archi rappresentano, rispettivamente, stati e transizioni
- Ogni arco è etichettato da un simbolo di input
- Lo stato iniziale viene evidenziato mediante una freccia entrante
- Gli stati finali sono indicati tramite doppia cerchiatura oppura da una freccia uscente

Rappresentazione di un AFD
- La rappresentazione di un AFD coincide "essenzialmente" con la rappresentazione della funzione di transizione δ
- Questa può essere semplicemente data come tabella, con m = |Q| righe (stati dell'automa) ed n = |Σ| colonne (alfabeto di input)

Simulazione di automi deterministici
- L'algoritmo riceve in ingresso M (automa) e l'input X per M e produce l'output che darebbe M su input X
- Nella descrizione dell'algoritmo (in pseudocodice) si suppone che:
    - l'input X sia terminato dal carattere $   
    - tale carattere non appartiene all'alfabeto Σ dell'automa
    - se, per una determinata coppia stato-simbolo, <q, x>, la funzione di transizione è indefinita, si pone δ(q, x) = ⊥

Algoritmo AFD-Sim
1: q ← q0 --> assegnazione stato iniziale
2: x ← nextchar(X) --> assegnazione primo carattere dell'input
3: while (x != $) do --> finché l'input è diverso dal carattere terminatore $ rimango dentro al ciclo
4:    if δ(q, x) != ⊥ then --> finchè la funzione di transizione non è indefinitia
5:       q ← δ(q, x) --> assegnazione del nuovo stato
6:    else
7:       reject
8:    x ← nextchar(X) --> scorrimento dell'input
9: if q ∈ Qf then --> se lo stato attuale appartiene ad uno degli stati finali 
10:   accept --> accettazione dell'input
11: else
12:   reject