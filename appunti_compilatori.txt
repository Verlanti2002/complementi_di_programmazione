24/09/24

Compilatore: componente di una cosidetta "toolchain" di programmi il cui obiettivo è creare eseguibili a partire da programmi sorgenti

Altri componenti della "toolchain":
    - precompilatore: inclusione di file (#include), definizione/espansione di macro (#define) e compilazione condizionale (#ifdef, #if, #ifndef)
    - assemblatore: genera il codice oggetto 
    - linker (statico o dinamico): collega le librerie statiche e crea l'eseguibile finale

sorgente (hw.cpp) --> PREPROCESSORE --> pre elaborato o translation unit (hw.ii) --> COMPILATORE (cc1plus) --> assembly (hw.s) --> ASSEMBLER (as) --> codice oggetto (hw.o) --> LINKER (ld) --> eseguibile (hw) --> processo in esecuzione (input: librerie dinamiche) --> output

GCC (GNU Compiler Collection): suite in grado di compilare principalmente programmi in C/C++
    - cpp: preprocessore C/C++
    - cc1/cc1plus: compilatore vero e proprio
    - as: programma assemblatore
    - ld: linker

- Preprocessing
    > cpp -o hw.ii hw.cpp
- Compilazione
    > cc1plus -o hw.s hw.ii 2>/dev/null
- Assemblaggio
    > as -o hw.o hw.s
- Linking (collect2: invocatore del linker)
    > g++ -v -o hw.o --> il driver g++ invoca il linker usando il comando collect2
- Esecuzione
    ./hw

Compilatore vs Interprete

Compilatore
Nei linguaggi compilati, il codice sorgente viene tradotto interamente in codice macchina da un programma chiamato compilatore prima dell'esecuzione
sorgente --> compilatore --> eseguibile (in linguaggio macchina) --> macchina fisica (interpreta il binario) --> output
    - Compilazione anticipata: prima compilazione poi esecuzione
    - Velocità di esecuzione: l'esecuzione è più veloce in quanto il codice è già tradotto in istruzioni macchina
    - Verifica di errori: la maggior parte degli errori (sintattici o semantici) viene rilevata durante la compilazione
    - Portabilità limitata: il codice compilato è strettamente legato all'architettura della macchina su cui è stato compilato 

Interprete
Nei linguaggi interpretati, il codice sorgente viene tradotto ed eseguito riga per riga da un programma chiamato interprete
L'interprete legge il codice sorgente e lo esegue direttamente, senza produrre un file eseguibile seperato
sorgente --> interprete --> output
    - Velocità di esecuzione: più lento nell'esecuzione, poichè l'interprete deve tradurre ogni istruzione mentre viene eseguita (inefficiente, spende molto tempo nell'analisi dell'input)
    - Flessibilità: maggiore flessibilità e portabilità poichè l'interprete può essere eseguito su diverse piattaforme
    - Debugging più semplice: eseguendo il codice riga per riga risulta più facile testare piccole porzioni di codice
    - Portabilità: il codice sorgente può essere eseguito su qualsiasi macchina che abbia un interprete compatibile 

Linguaggi ibridi: vengono prima compilati in bytecode, un formato intermedio, e poi eseguiti da una macchina virtuale (JVM per Java)
Anche Python a volte utilizza una compilazione intermedia in bytecode (.pyc) ma viene comunque interpretato da una macchina virtuale (l'interprete Python)

In generale, un'implementazione interpretata include anche un traduttore che è essenzialmente identico al front-end di un compilatore

OSSERVAZIONE: il bytecode è tipicamente l'assembler della macchina virtuale

Compilatore: modulo che effettua la traduzione da sorgente ad una qualche rappresentazione intermedia, esso è suddiviso a sua volta in 3 moduli:
    - front-end (compilatori e interpreti): prende il sorgente e produce una sua rappresentazione intermedia indipendente dal linguaggio e dalla macchina
    - middle-end: esegue un'ottimizzazione del codice intermedio
    - back-end: produce il codice per l'architettura target

Il front/middle/back-end è composto da 4/1/2 fasi
sequenza di caratteri --> ANALIZZATORE LESSICALE --> sequenza di token --> ANALIZZATORE SINTATTICO --> albero sintattico --> GENERATORE DI CODICE INTERMEDIO --> rappresentazione intermedia | --> GENERATORE DI CODICE --> codice macchina --> OTTIMIZZATORE DIPENDENTE DALLA TECNOLOGIA --> codice macchina

ANALIZZATORE LESSICALE (LEXER): raggruppa sequenze di caratteri in oggetti (TOKEN)
ANALIZZATORE SINTATTICO (PARSER): start run, prende una sequenza di token e indica se essi formano una struttura linguistica legale del linguaggio (correttezza sintattica)
ANALIZZATORE SEMANTICO: analisi dei tipi, controlla la corrispondenza del numero di parametri di una procedura
GENERATORE DI CODICE INTERMEDIO: produce un codice lineare
TABELLA DEI SIMBOLI: struttura dati (dizionario: mapping chiave-valore) che memorizza i simboli incontrati nell'analisi del sorgente

Esempio pratico:
position = initial + rate * 60

Analizzatore lessicale:
⟨id, 1⟩ (=) ⟨id, 2⟩ (+) ⟨id, 3⟩ (*) (60)

Analizzatore sintattico:
⟨id, 1⟩ = ⟨id, 2⟩ + ⟨id, 3⟩ * 60

Analizzatore semantico:
⟨id, 1⟩ = ⟨id, 2⟩ + ⟨id, 3⟩ * inttofloat(60)

Generatore di codice intermedio:
t1 = inttofloat(60)
t2 = id3 * t1
t3 = id2 + t2
id1 = t3

Ottimizzatore di codice:
t1 = id3 * 60.0
id1 = id2 + t1

Generatore di codice:
LDF R2, id3
MULF R2, R2, #60.0
LDF R1, id2
ADDF R1, R1, R2
STF id1, R1

Type Checking: controllo dei tipi (statico --> controllo a tempo di compilazione | dinamico --> controllo a tempo di esecuzione)
Scoping rules: regole che descrivono la visibilità (o scope) delle variabili all'interno del programma
Ambiente: mapping fra nomi e locazioni di memoria
Memoria: mapping fra locazioni di memoria e valori
Linguaggio funzionale: caratterizzato da un mapping diretto tra nome e valore, il programmatore ha visibilità del solo ambiente
l-value (left value): entità che ha una posizione in memoria e quindi può essere assegnato o modificato
    - ha un indirizzo in memoria
    - può essere usato per ricevere un valore
r-value (right value): rappresenta un qualsiasi valore o contenuto temporaneo che può essere assegnato (ma non modificato) a un l-value
    - non ha un indirizzo in memoria associato 
    - non può essere assegnato o modificato direttamente

26/09/24

Linguaggi formali: linguaggi definiti mediante un qualche apparato formale di natura matematica
    - è possibile stabilire se una "frase" è corretta (sintassi)
    - è possibile attribuire un ben preciso significato, senza ambiguità (semantica)

Linguaggi formali in informatica
- Linguaggi di programmazione: C/C++, Java, Python, ...
- Linguaggi di marcatura: HTML. XML, LaTeX
- Linguaggi di interrogazione: SQL, SPARQL, GraphLog
- Linguaggi di configurazione: sendmail, apache, iptables

Alfabeto: insieme finito di simboli (detti anche caratteri)
    - Σ per indicare un generico alfabeto
    - (a, b e c) per indicare un generico carattere utilizziamo le lettere iniziali dell'alfabeto latino

Stringhe: sequenza di caratteri ∈ Σ
    - per indicare una stringa generica utilizziamo le ultime lettere dell'alfabeto latino (w, x, y, z)
    - per indicare una stringa generica utilizziamo le prime lettere dell'alfabeto greco (α, β, γ)
    - per indicare una stringa speciale (formata da zero caratteri) o vuota usiamo ϵ
    - per evitare ambiguità racchiuderemo le stringhe fra coppie di apici (o doppi apici)

Operazioni sulle stringhe
- Concatenazione: unione di due stringhe, una di seguito all'altra
    x = Linguaggi y = formali --> xy = Linguaggiformali
    - associativa ( (A*B)*C = A*(B*C) ), ma non commutativa (A*B != B*A)
    - la stringa vuota ϵ è l'elemento neutro della concatenazione
- |x| lunghezza della stringa x
- xi carattere in posizione i, i = 0, . . . , |x| − 1
- Una sottostringa di x é una stringa formata dai caratteri xi, xi+1, . . . , xj, per opportuni valori di i e j, 0 ≤ i ≤ j < n
- x^R indica la stringa ottenuta rovesciando i caratteri di x
    x = Roma --> x^R = amoR

Linguaggi
Un linguaggio su un dato alfabeto Σ è un insieme di stringhe di caratteri (o simboli) ∈ Σ
- Esempio di linguaggio con un numero di stringhe finito
    L2 = {00,01,10,11} --> definito su B e formato da 4 stringhe

Operazioni con i linguaggi
- operazioni insiemistiche (unione, intersezione, differenza, ...)
- concatenazione
    M e N linguaggi dello stesso alfabeto Σ
    L = MN = {z ∈ Σ* : ∃ x ∈ M, ∃ y ∈ N | z = xy}
    elemento neutro: stringa vuota {ϵ}
- potenza n-esima
    L^0 = {ϵ}
    L^n = L^n−1 * L, n > 0
- chiusura (riflessiva)
    L* = ∪ (n=0 to ∞) L^n = L^0 ∪ L^1 ∪ L^2 ∪ ...
    Esempio:
        B* = ∪ (n=0 to ∞) {0,1}^n
        = {0, 1}^0 ∪ {0, 1}^1 ∪ {0, 1}^2 ∪ . . .
        = {ϵ} ∪ {0, 1} ∪ {00, 01, 10, 11} . . .
        B*: insieme di tutte le stringhe binarie
    Σ*: insieme di tutte le stringhe su un alfabeto Σ
- chiusura (non riflessiva): L^+ = LL*
    L^+ = ∪ (n=1 to ∞) L^n = L^1 ∪ L^2 ∪ ...
- riflessione di linguaggio L su alfabeto Σ
    L^R = {x ∈ Σ* : ∃y ∈ L | x = y^R}
- |L| numero stringhe di un linguaggio finito
    |L| = N se L è infinito

Specifica di linguaggi
Se il linguaggio è infinito è comunque possibile descriverlo con quantità finita di informazione
Esempio:
    L0 = {x ∈ B* | x = y0, y ∈ B*}

Specifica riconoscitiva
Si tratta di definire il linguaggio tramite un algoritmo decisionale, ossia il cui output è binario: yes/no True/False, 0/1, ...
Dato A un algoritmo di decisione, Σ alfabeto generico: 
La = {x ∈ Σ* | A(x) = True}
Il linguaggio C++ è l'insieme delle stringhe sull'alfabeto ASCII (programmi) per cui il compilatore C++ (l'algoritmo) non produce errore

Specifica generativa
Si danno delle "regole" con cui è possibile generare tutte e sole le stringhe del linguaggio che si vuole specificare
I formalismi più importanti sono: --> strumenti fondamentali per definire il comportamento di lexer e parser
    - espressioni regolari
    - grammatica context-free

Linguaggi regolari
Un linguaggio L su alfabeto Σ = {a1, ..., an} si dice regolare se può essere espresso usando un numero finito di operazioni di 
concatenazione, unione e chiusura riflessiva a partire dai suoi linguaggi unitari {a1}, ..., {an}
    - {ϵ}, {a1}, . . . , {an} sono linguaggi regolari
    - se R1 ed R2 sono linguaggi regolari, allora R1 ∪ R2 e R1R2 sono linguaggi regolari
    - se R è un linguaggio regolare allora R* è un linguaggio regolare 

Linguaggio unitario: linguaggio costituito da un singolo carattere di Σ
Esempio:
    - {C++} è concatenazione dei linguaggi unitari {C}, {+}, {+}
    - {Python} è concatenazione dei linguaggi unitari {P}, {y}, {t}, {h}, {o}, {n}
    - {x,y,z} è regolare perchè esprimibile come unione dei linguaggi regolari {x}, {y} e {z}
    - {C++,Python} è regolare perchè unione di due linguaggi regolari
Ogni linguaggio finito è esprimibile come unione di concatenazioni di linguaggi unitari

Espressioni regolari
Dato un alfabeto Σ sono un formalismo (cioè a loro volta sono linguaggi) per definire linguaggi regolari
Le epressioni regolari pure (e.r) riflettono le costruzioni dei linguaggi regolari 
    Base
        - ϵ è un'espressione regolare che denota il linguaggio composto dalla sola stringa vuota ϵ
        - per ogni a ∈ Σ, a è un'e.r. che denota il linguaggio unitario {a}
    Ricorsione Se E ed F sono e.r. che denotano, rispettivamente, i linguaggi E ed F, allora la scrittura:
        - EF è un'e.r. che denota il linguaggio EF (concatenazione)
        - E|F (o anche E + F) è un'e.r. che denota il linguaggio E ∪ F (unione)
        - E* è un'e.r. che denota il linguaggio E* (chiusura riflessiva)
    Parentesi  Se E è un'e.r., la scrittura (E) è un'e.r. equivalente alla prima, cioè che denota lo stesso insieme di stringhe

01/10/24

prefisso: sottostringa che sta all'inizio

Esempi:
- L'espressione regolare 0|1*10 su B (interpretabile come 0|((1*)10), in base alle regole di precedenza) denota il linguaggio R1 = {0, 10, 110, 1110, . . .}
- Il linguaggio R1 è chiaramente differente dal linguaggio R2 su B definito dall'espressione regolare (0|1)*10, che consiste di tutte le stringhe binarie che terminano con 10
- Posto Σ = {a, b, c}, l'espressione regolare a(b|c)*a denota il linguaggio R3 su Σ costituito dalle stringhe che iniziano e terminano con il carattere a e che non contengono altre a
- La scrittura (1|01)*(0|ϵ) denota il linguaggio delle stringhe su B di lunghezza almeno 1 che non contengono due caratteri 0 consecutivi

Problemi pratici
- Nelle regole di composizione delle e.r. non esiste la possibilità di esprimere la negazione di un carattere a
- Allo stesso modo non esiste un operatore per indicare una potenza definita di un insieme di stringhe

Metacaratteri e regole aggiuntive
- Come sappiamo, i simboli dell'alfabeto sono detti anche "caratteri"
- Nella descrizione formale del linguaggio si usano però anche altri simboli, che non fanno parte dell'alfabeto
- Nel caso delle e.r., esempi di simboli usati per scopi descrittivi sono le parentesi e i simboli * e |
    Tali simboli sono detti metacaratteri (simboli astratti)
- Nelle e.r. estese (definite, ad es. sull'alfabeto ASCII) esistono metacaratteri che denotano opportuni sotto-insiemi di caratteri dell'alfabeto
    Ad esempio:
        - la scrittura [:alpha:] denota l'insieme dei caratteri alfabetici (rispetto al locale corrente)
        - [:digit:] denota l'insieme delle cifre decimali
        - [:alnum:] denota l'insieme dei caratteri alfabetici e numerici (le cifre)
- Le parentesi quadre sono metacaratteri
- Caratteri e metacaratteri inclusi fra parentesi quadre si intendono in or
    Ad esempio [_[:alnum:]] denota il l'insieme dei caratteri alfanumerici unito il "trattino basso" (underscore)
- Il simbolo ^ come primo carattere all'interno di una coppia di parentesi quadre denota l'insieme dei caratteri dell'alfabeto, ad esclusione dei simboli che seguono
    Ad esempio [^[:alnum:]] denota l'insieme di tutti i caratteri che non sono alfanumerici

Problemi di matching
- Nella parte di front-end di compilatori e interpreti, il programma (analizzatore lessicale o lexer) riceve in input il testo (programma da compilare/eseguire)
  e un insieme di espressioni regolari, il lexer deve dire quale espressione descrive un opportuno prefisso del testo ancora da analizzatore
    Ad esempio, se l'input ancora da esaminare fosse 
        formula = 2*x**2
    il prossimo match trovato dal lexer dovrebbe essere formula (un caso di identificatore) piuttosto che for (un caso di parola chiave)

Esercizi di prova
1. Scrivere e.r per i linguaggi sull'alfabeto {a,b} composti dalle stringhe contenenti:
    - al più due a --> b* | b*ab* | b*ab*ab*
    - un numero dispari b --> (a*ba*b)*a*ba*
2. Scrivere un'e.r. per il linguaggio sull'alfabeto {a, b, c} così definito: {a^n b^m c^k | m = 0 ⇒ k = 3} --> prima tutte le a
    a*(bb*c* | ccc)
3. Scrivere un'e.r. per il linguaggio sull'alfabeto {a, b, c}, costituito dalle stringhe in cui ogni occorrenza di b è seguita da almeno una c  
    (a | c | bc)*
4. Qual è il linguaggio descritto dalla seguente espressione regolare estesa: [ab]{3} * [ab] --> [ab] = a | b
    abbaab, aaaabb, ...
    ((a | b)(a | b)(a | b)) (a | b) --> e.r base
5. Scrivere un'espressione regolare per definirw il linguaggio delle stringhe sull'alfabeto {0, 1} che non contengono tre 1 di fila
    (0 | 10 | 110) * (1 | 11)0*

Espressioni regolari che ci saranno utili
- E.r. estesa per identificatori composti dal carattere underscore, lettere e numeri e inizianti per lettera o underscore
    [a − zA − Z_][a − zA − Z0 − 9_]∗
- E.r. per numeri in virgola fissa (interi inclusi)
    (0|[1 − 9][0 − 9]∗)\.?[0 − 9]∗
- E.r. per numeri in virgola mobile
    (0|[1 − 9][0 − 9]∗)\.?[0 − 9] ∗ ([eE][−+]?[0 − 9]+)

Le espressioni regolari sono lo strumento che utilizzeremo per programmare un lexer

Lexer (analizzatore lessicale)
- Il compito principale del lexer (analizzatore lessicale) è di trasformare la sequenza di caratteri
che costituisce l'input del compilatore (cioè il programma) in una sequenza di token
- Il lexer agisce come subroutine del parser e, ad ogni chiamata, restituisce a quest'ultimo un token

Token --> oggetto astratto (rappresentato con una struct) con le seguenti proprietà: --> esempi di token: numeri, identificatori e le parole riservate di un linguaggio di programmazione
    - deve avere un nome (token name, sempre in grassetto) --> identificatore che deve avere lo stesso significato per lexer e parser
    - alcuni token (numeri, identificatori e costanti letterali) hanno anche un token value 
    - alcuni altri token (keyword, parentesi, operatori relazionali o aritmetici)
    - la posizione dove si trova il token (location)

Esempio:
Supponiamo che la porzione di input da analizzare abbia come prefisso
    somma = 0
Alle richieste del parser, il lexer restituisce in sequenza i token
    - (id, "somma")
    - assignment
    - (number,0)

Pattern, lessemi e (nomi di) token

Token name          Pattern                     Esempio di lessema (sottostringa matchata)
id                  [:alpha:][:alnum:]*         pippo1
number              [+- ][1-9][:digit:]*        -3.14
comparison          < | > | <= | >= | = | !=    <   
literal             [:alpha:]                   "Pi greco"
if                  if                          if
while               while                       while

Compiti del lexer
- Il lexer è l'unico modulo del compilatore che legge l'input testuale
- Lo scanner è un modulo separato del lexer che effettua la lettura del testo
- Il lexer vero e proprio, nel processo di tokenizzazione, procede anche a riconoscere e "filtrare" commenti, spazi e altri caratteri di separazione
- Deve inoltre associare gli eventuali errori trovati da altri moduli del compilatore alle posizione dove tali errori si sono verificati

In linux:
flex --> generatore di lexer
bison --> generatore di parser

Lex: strumento per generare di analizzatori lessicali
    - software in grado di generare automaticamente un altro programma che riconosce stringhe di un linguaggio regolare
    - l'input del programma Lex è costituito da un insieme di espressioni regolari / pattern da riconoscere
    - inoltre, ad ogni espressione regolare E, l'utente associa un'azione, espressa sotto forma di codice in linguaggio C/C++
    - tale codice andrà in esecuzione quando l'analizzatore lessicale prodotto da Lex avrà riconosciuto un lessema descritto da E

Schema d'uso di Lex
Sorgente Lex (lexer.l) --> Compilatore Lex --> lex.yy.c / lex.yy.cc
lex.yy.cc / lex.yy.cc --> Compilatore C/C++ --> a.out
charstring --> Running a.out --> token sequence

Struttura di un programma Lex
- Un generico programma Lex contiene tre sezioni, separate dal dalla sequenza %%
    Dichiarazioni   
    %%
    Regole di traduzione
    %%
    Funzioni ausiliarie
- La sezione "Dichiarazioni" può contenere definizione di costanti/variabili, specifica di header file e, soprattutto, definizioni regolari, cioè espressioni regolari "con un nome"
- La sezione intermedia specifica le "regole di traduzione", ovvero le descrizioni delle azioni che devono essere eseguite a seguito del riconoscimento dell'istanza di un pattern
    riconoscimento di un lessema che matcha un'espressione regolare
- L'ultima sezione può contenere funzioni aggiuntive

Esempio di "tokenizer":

%{
# include <iostream >
using namespace std ;
%}

DIGIT [0 -9]
DIGIT1 [1 -9]

/* read only one input file */
% option noyywrap

%%
"+" { cout << " operatore <" << yytext [0] << ">" << endl ; }
"-" { cout << " operatore <" << yytext [0] << ">" << endl ; }
"=" { cout << " operatore <" << yytext [0] << ">" << endl ; }
{ DIGIT1 }{ DIGIT }* { cout << " numero <" << yytext << ">" << endl ; }
. { cout << " Token sconosciuto <" << yytext [0] << ">" << endl ; }
%%

int main (int argc , char ** argv ) {
    FlexLexer * lexer = new yyFlexLexer ;
    lexer -> yylex ();
    return 0;
}

Analisi del codice
- Al termine dell'esecuzione, yylex invoca il metodo yywrap
- Questo può quindi essere utilizzato per aprire un secondo file di input e chiamare nuovamente yylex
- Se viene utilizzata l'opzione noyywrap, il metodo yywrap non viene invocato e non deve essere ridefinito

yytext: varabile globale in cui il lexer va a mettere il lessema che ha matchato il pattern (o espressione regolare)
% option noyywrap --> opzione che permette di leggere solo un file di input

flex++ -o simpletok.cc simpletok.l --> compilazione del programma Lex
clang++/g++ -o simpletok simpletok.cc --> compilazione del file C++

03/10/24